{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "import random\n",
    "from ipywidgets import Button, Output, VBox\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# ----------------------------\n",
    "# Adaline Class\n",
    "# ----------------------------\n",
    "\n",
    "class Adaline:\n",
    "    def __init__(self, learning_rate=0.00001, n_iterations=485):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.errors_ = []  # Track the Mean Squared Error (MSE) for each epoch\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights with small random values\n",
    "        self.weights = np.random.normal(0, 0.01, size=(1 + X.shape[1]))\n",
    "        for epoch in range(self.n_iterations):\n",
    "            # Calculate net input\n",
    "            net_input = self.net_input(X)\n",
    "\n",
    "            # Activation function (identity for Adaline)\n",
    "            output = self.activation(net_input)\n",
    "\n",
    "            # Calculate errors\n",
    "            errors = y - output\n",
    "\n",
    "            # Update weights\n",
    "            self.weights[1:] += self.learning_rate * X.T.dot(errors)  # Feature weights\n",
    "            self.weights[0] += self.learning_rate * errors.sum()      # Bias term\n",
    "\n",
    "            # Calculate Mean Squared Error (MSE)\n",
    "            mse = np.mean(errors**2)\n",
    "            self.errors_.append(mse)  # Store the MSE for this epoch\n",
    "\n",
    "            # Early stopping if MSE is very small\n",
    "            if mse < self.learning_rate:  # Adjust this threshold as needed\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break;\n",
    "\n",
    "            # Log the progress\n",
    "            print(f\"Epoch {epoch + 1}: Mean Error = {mse:.5f}, Weights Mean = {np.mean(self.weights):.5f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        # Calculate the linear combination of weights and inputs\n",
    "        return np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Linear activation function (identity function for Adaline)\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make binary predictions based on a threshold\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)\n",
    "\n",
    "# ----------------------------\n",
    "# Madaline Class\n",
    "# ----------------------------\n",
    "class Madaline:\n",
    "    def __init__(self, n_adalines=3, learning_rate=0.00001, n_iterations=485):\n",
    "        self.n_adalines = n_adalines\n",
    "        self.adalines = [Adaline(learning_rate, n_iterations) for _ in range(n_adalines)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feature_split = np.array_split(X, self.n_adalines, axis=1)\n",
    "        for i, adaline in enumerate(self.adalines):\n",
    "            adaline.fit(feature_split[i], y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        feature_split = np.array_split(X, self.n_adalines, axis=1)\n",
    "        predictions = np.array([adaline.predict(split) for adaline, split in zip(self.adalines, feature_split)])\n",
    "        return np.where(predictions.mean(axis=0) >= 0.5, 1, 0)\n",
    "\n",
    "# ----------------------------\n",
    "# Shape Generation\n",
    "# ----------------------------\n",
    "def generate_shape(shape_type, image_size=64, noise_level=0.1):\n",
    "    \"\"\"Generate a simple shape image with noise.\"\"\"\n",
    "    image = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "    center = (image_size // 2, image_size // 2)\n",
    "    size = int(image_size * 0.3)\n",
    "\n",
    "    if shape_type == 'circle':\n",
    "        cv2.circle(image, center, size, 255, -1)\n",
    "    elif shape_type == 'square':\n",
    "        top_left = (center[0] - size, center[1] - size)\n",
    "        bottom_right = (center[0] + size, center[1] + size)\n",
    "        cv2.rectangle(image, top_left, bottom_right, 255, -1)\n",
    "    elif shape_type == 'triangle':\n",
    "        points = np.array([\n",
    "            [center[0], center[1] - size],\n",
    "            [center[0] - size, center[1] + size],\n",
    "            [center[0] + size, center[1] + size]\n",
    "        ], np.int32)\n",
    "        cv2.fillPoly(image, [points], 255)\n",
    "    elif shape_type == 'pentagon':\n",
    "        points = np.array([\n",
    "            [center[0], center[1] - size],\n",
    "            [center[0] - size, center[1] - size // 2],\n",
    "            [center[0] - size // 2, center[1] + size],\n",
    "            [center[0] + size // 2, center[1] + size],\n",
    "            [center[0] + size, center[1] - size // 2]\n",
    "        ], np.int32)\n",
    "        cv2.fillPoly(image, [points], 255)\n",
    "    elif shape_type == 'hexagon':\n",
    "        points = np.array([\n",
    "            [center[0] - size, center[1]],\n",
    "            [center[0] - size // 2, center[1] - size],\n",
    "            [center[0] + size // 2, center[1] - size],\n",
    "            [center[0] + size, center[1]],\n",
    "            [center[0] + size // 2, center[1] + size],\n",
    "            [center[0] - size // 2, center[1] + size]\n",
    "        ], np.int32)\n",
    "        cv2.fillPoly(image, [points], 255)\n",
    "\n",
    "    noise = np.random.normal(0, noise_level, image.shape)\n",
    "    noisy_image = image + noise * 255\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "def create_dataset(n_samples=485):\n",
    "    \"\"\"Create a dataset of shapes.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    shapes = ['circle', 'square', 'triangle', 'pentagon', 'hexagon']\n",
    "    for _ in range(n_samples):\n",
    "        shape = random.choice(shapes)\n",
    "        image = generate_shape(shape)\n",
    "        X.append(image.flatten())\n",
    "        y.append([1 if shape == s else 0 for s in shapes])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "\n",
    "def predict_shape(image, models):\n",
    "    \"\"\"Predict the shape using improved feature extraction.\"\"\"\n",
    "    processed_image, circularity = preprocess_image(image)\n",
    "    image_scaled = scaler.transform([processed_image.flatten()])\n",
    "\n",
    "    predictions = {}\n",
    "    for shape, model in models.items():\n",
    "        adaline_pred = float(model['adaline'].predict(image_scaled)[0])\n",
    "        madaline_pred = float(model['madaline'].predict(image_scaled)[0])\n",
    "        base_prob = (adaline_pred + madaline_pred) / 2\n",
    "\n",
    "        # Adjust probabilities based on circularity\n",
    "        if shape == 'circle' and circularity > 0.9:\n",
    "            base_prob = max(base_prob, 0.9)\n",
    "        elif shape == 'square' and circularity > 0.9:\n",
    "            base_prob *= 0.1\n",
    "\n",
    "        predictions[shape] = base_prob\n",
    "\n",
    "    # Normalize probabilities\n",
    "    total = sum(predictions.values())\n",
    "    if total > 0:\n",
    "        predictions = {k: v/total for k, v in predictions.items()}\n",
    "\n",
    "    return max(predictions.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "def calculate_accuracy():\n",
    "    \"\"\"Calculate the accuracy of the models.\"\"\"\n",
    "    correct = 0\n",
    "    total = len(X_test)\n",
    "    for i in range(total):\n",
    "        actual_shape = shapes[np.argmax(y_test[i])]\n",
    "        predicted_shape = predict_shape(X_test[i].reshape(64, 64), shape_models)\n",
    "        if actual_shape == predicted_shape:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "from ipywidgets import FileUpload\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Widget for uploading an image\n",
    "upload = FileUpload(accept='image/*', multiple=False)\n",
    "est_image_scaled = scaler.transform([processed_image.flatten()])\n",
    "\n",
    "\n",
    "def enhance_image_preprocessing(image_array):\n",
    "    \"\"\"\n",
    "    Enhanced image preprocessing with better feature extraction\n",
    "    \"\"\"\n",
    "    # Ensure proper image scaling\n",
    "    image_array = cv2.normalize(image_array, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(image_array, (5, 5), 0)\n",
    "    \n",
    "    # Use adaptive thresholding for better binarization\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        blurred,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11,\n",
    "        2\n",
    "    )\n",
    "    \n",
    "    # Clean up the binary image\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        return image_array, {\n",
    "            'circularity': 0,\n",
    "            'corners': 0,\n",
    "            'aspect_ratio': 1,\n",
    "            'convexity': 0\n",
    "        }\n",
    "    \n",
    "    # Get the largest contour\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate shape features\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    perimeter = cv2.arcLength(largest_contour, True)\n",
    "    hull = cv2.convexHull(largest_contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    \n",
    "    # Calculate shape metrics\n",
    "    circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0\n",
    "    convexity = area / hull_area if hull_area > 0 else 0\n",
    "    \n",
    "    # Approximate the contour to count corners\n",
    "    epsilon = 0.04 * perimeter\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "    corners = len(approx)\n",
    "    \n",
    "    # Calculate aspect ratio\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    aspect_ratio = float(w)/h if h > 0 else 1\n",
    "    \n",
    "    # Create feature image\n",
    "    feature_image = np.zeros_like(binary)\n",
    "    cv2.drawContours(feature_image, [largest_contour], -1, 255, -1)\n",
    "    \n",
    "    features = {\n",
    "        'circularity': circularity,\n",
    "        'corners': corners,\n",
    "        'aspect_ratio': aspect_ratio,\n",
    "        'convexity': convexity\n",
    "    }\n",
    "    \n",
    "    return feature_image, features\n",
    "\n",
    "def improved_predict_shape(image, models):\n",
    "    \"\"\"\n",
    "    Improved shape prediction using multiple features\n",
    "    \"\"\"\n",
    "    processed_image, features = enhance_image_preprocessing(image)\n",
    "    image_scaled = scaler.transform([processed_image.flatten()])\n",
    "    \n",
    "    predictions = {}\n",
    "    for shape, model in models.items():\n",
    "        # Get base predictions from both models\n",
    "        adaline_pred = float(model['adaline'].predict(image_scaled)[0])\n",
    "        madaline_pred = float(model['madaline'].predict(image_scaled)[0])\n",
    "        base_prob = (adaline_pred + madaline_pred) / 2\n",
    "        \n",
    "        # Apply feature-based adjustments\n",
    "        if shape == 'circle':\n",
    "            if features['circularity'] > 0.9 and features['corners'] <= 8:\n",
    "                base_prob *= 1.5\n",
    "            elif features['circularity'] < 0.5:\n",
    "                base_prob *= 0.5\n",
    "                \n",
    "        elif shape == 'square':\n",
    "            if features['corners'] == 4 and 0.95 <= features['aspect_ratio'] <= 1.05:\n",
    "                base_prob *= 1.5\n",
    "            elif features['corners'] != 4:\n",
    "                base_prob *= 0.5\n",
    "                \n",
    "        elif shape == 'triangle':\n",
    "            if features['corners'] == 3:\n",
    "                base_prob *= 1.5\n",
    "            elif features['corners'] > 4:\n",
    "                base_prob *= 0.3\n",
    "                \n",
    "        elif shape == 'pentagon':\n",
    "            if features['corners'] == 5:\n",
    "                base_prob *= 1.5\n",
    "            elif features['corners'] < 4 or features['corners'] > 6:\n",
    "                base_prob *= 0.3\n",
    "                \n",
    "        elif shape == 'hexagon':\n",
    "            if features['corners'] == 6:\n",
    "                base_prob *= 1.5\n",
    "            elif features['corners'] < 5 or features['corners'] > 7:\n",
    "                base_prob *= 0.3\n",
    "        \n",
    "        predictions[shape] = max(0, min(1, base_prob))  # Clamp between 0 and 1\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    total = sum(predictions.values())\n",
    "    if total > 0:\n",
    "        predictions = {k: v/total for k, v in predictions.items()}\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def improved_image_upload_handler(change):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        if upload.value:\n",
    "            uploaded_file = list(upload.value.values())[0]\n",
    "            content = uploaded_file['content']\n",
    "            \n",
    "            # Open and convert to grayscale\n",
    "            image = Image.open(io.BytesIO(content)).convert('L')\n",
    "            original_size = image.size\n",
    "            \n",
    "            # Resize and convert to numpy array\n",
    "            resized_image = image.resize((64, 64))\n",
    "            test_image = np.array(resized_image)\n",
    "            \n",
    "            # Get predictions with improved method\n",
    "            shape_probabilities = improved_predict_shape(test_image, shape_models)\n",
    "            \n",
    "            # Process image for display\n",
    "            processed_image, features = enhance_image_preprocessing(test_image)\n",
    "            \n",
    "            # Get predicted shape and confidence\n",
    "            predicted_shape = max(shape_probabilities.items(), key=lambda x: x[1])[0]\n",
    "            confidence = shape_probabilities[predicted_shape] * 100\n",
    "            \n",
    "            # Display results\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Original image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(np.array(image), cmap='gray')\n",
    "            plt.title(f\"Original Image\\nSize: {original_size}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Processed image\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(processed_image, cmap='gray')\n",
    "            plt.title(\"Processed Image\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Feature visualization\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Shape Analysis\")\n",
    "            \n",
    "            # Display shape probabilities and features\n",
    "            info_text = f\"Predicted: {predicted_shape.capitalize()}\\n\"\n",
    "            info_text += f\"Confidence: {confidence:.2f}%\\n\\n\"\n",
    "            info_text += \"Shape Probabilities:\\n\"\n",
    "            for shape, prob in shape_probabilities.items():\n",
    "                info_text += f\"{shape.capitalize()}: {prob*100:.1f}%\\n\"\n",
    "            info_text += \"\\nShape Features:\\n\"\n",
    "            for feature, value in features.items():\n",
    "                info_text += f\"{feature}: {value:.2f}\\n\"\n",
    "            \n",
    "            plt.text(0.1, 0.9, info_text, transform=plt.gca().transAxes, \n",
    "                    verticalalignment='top', fontfamily='monospace')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "# ----------------------------\n",
    "# Main Program\n",
    "# ----------------------------\n",
    "print(\"Initializing Shape Recognition System...\")\n",
    "X, y = create_dataset(485)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "shapes = ['circle', 'square', 'triangle', 'pentagon', 'hexagon']\n",
    "shape_models = {}\n",
    "\n",
    "for i, shape in enumerate(shapes):\n",
    "    print(f\"Training models for {shape}...\")\n",
    "    adaline = Adaline(learning_rate=0.00001, n_iterations=485)\n",
    "    adaline.fit(X_train_scaled, y_train[:, i])\n",
    "    madaline = Madaline(n_adalines=3, learning_rate=0.00001, n_iterations=485)\n",
    "    madaline.fit(X_train_scaled, y_train[:, i])\n",
    "    shape_models[shape] = {'adaline': adaline, 'madaline': madaline}\n",
    "\n",
    "accuracy = calculate_accuracy()\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Interactive Buttons for Colab\n",
    "# ----------------------------\n",
    "output = Output()\n",
    "\n",
    "def generate_shape_and_test(_):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        random_shape = random.choice(shapes)\n",
    "        test_image = generate_shape(random_shape)\n",
    "\n",
    "        predicted_shape = predict_shape(test_image, shape_models)\n",
    "        plt.imshow(test_image, cmap='gray')\n",
    "        plt.title(f'Generated: {random_shape}\\nPredicted: {predicted_shape}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def view_accuracy_and_plot(_):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\nCurrent Model Accuracy: {accuracy:.2%}\")\n",
    "        print(\"\\nPlotting Error Progression for Each Shape...\\n\")\n",
    "\n",
    "        # Plot error progression for each shape\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, shape in enumerate(shapes):\n",
    "            adaline_errors = shape_models[shape]['adaline'].errors_\n",
    "            madaline_errors = []\n",
    "            for adaline in shape_models[shape]['madaline'].adalines:\n",
    "                madaline_errors.append(adaline.errors_)\n",
    "\n",
    "            # Adaline errors\n",
    "            plt.subplot(len(shapes), 2, i * 2 + 1)\n",
    "            plt.plot(adaline_errors, label=f'Adaline - {shape.capitalize()}')\n",
    "            plt.title(f'{shape.capitalize()} - Adaline Error')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Mean Squared Error')\n",
    "            plt.legend()\n",
    "\n",
    "            # Madaline errors\n",
    "            plt.subplot(len(shapes), 2, i * 2 + 2)\n",
    "            for j, errors in enumerate(madaline_errors):\n",
    "                plt.plot(errors, label=f'Madaline Adaline-{j + 1}')\n",
    "            plt.title(f'{shape.capitalize()} - Madaline Error')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Mean Squared Error')\n",
    "            plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def exit_program(_):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Thank you for using the Shape Recognition System!\")\n",
    "\n",
    "button1 = Button(description=\"Generate and Test Random Shape\")\n",
    "button1.on_click(generate_shape_and_test)\n",
    "\n",
    "button2 = Button(description=\"View Model Accuracy and Errors\")\n",
    "button2.on_click(view_accuracy_and_plot)\n",
    "\n",
    "button3 = Button(description=\"Exit\")\n",
    "button3.on_click(exit_program)\n",
    "\n",
    "# Upload and output widgets\n",
    "upload = FileUpload(accept='image/*', multiple=False)\n",
    "upload.observe(on_image_upload, names='value')\n",
    "\n",
    "display(VBox([button1, button2, upload, button3]), output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
