{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naji course two ML \n",
    "\n",
    " https://www.vertopal.com/en/convert/ipynb-to-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(12,dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3 Operations\n",
    "\n",
    "Now that we know how to construct tensors and how to read from and write to their elements,we can begin to manipulate them with various mathematical operations. Among the most useful tools are the elementwise operations. These apply a standard scalar operation to each\n",
    "element of a tensor. For functions that take two tensors as inputs, elementwise operations apply some standard binary operator on each pair of corresponding elements. We can create an elementwise function from any function that maps from a scalar to a scalar.\n",
    "In mathematical notation, we denote such unary scalar operators (taking one input) by the signature f : R → R. This just means that the function maps from any real number ontosome other real number. Most standard operators can be applied elementwise including unary operators like exp(x)\n",
    "\n",
    "Maintenant que nous savons comment construire des tenseurs et comment lire et écrire dans leurs éléments, nous pouvons commencer à les manipuler avec diverses opérations mathématiques. Parmi les outils les plus utiles figurent les opérations élément par élément. Ceux-ci appliquent une opération scalaire standard à chaque élément d'un tenseur. Pour les fonctions qui prennent deux tenseurs en entrée, les opérations élément par élément appliquent un opérateur binaire standard sur chaque paire d'éléments correspondants. Nous pouvons créer une fonction élément par élément à partir de n'importe quelle fonction qui mappe d'un scalaire à un scalaire.\n",
    "En notation mathématique, nous dénotons de tels opérateurs scalaires unaires (prenant une entrée) par la signature f : R → R. Cela signifie simplement que la fonction mappe à partir de n'importe quel nombre réel sur un autre nombre réel. La plupart des opérateurs standard peuvent être appliqués élément par élément, y compris les opérateurs unaires comme exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
       "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we denote binary scalar operators, which map pairs of real numbers to a (single) real number via the signature f : R x R → R. Given any two vectors u and v of the same shape, and a binary operator f , we can produce a vector c = F(u, v) by setting ci ← f(ui,vi) for all i, where ci, ui, and vi are the ith elements of vectors c, u, and v. Here, we produced the vector-valued $F :  R^{d} →R^{d} $ by lifting the scalar function to an elementwise vector operation. The common standard arithmetic operators for addition (+), subtraction (-), multiplication (*), division (/), and exponentiation (**) have all been lifted to elementwise operations for identically-shaped tensors of arbitrary shape.\n",
    "\n",
    "De même, nous désignons les opérateurs scalaires binaires, qui mappent des paires de nombres réels à un nombre réel (unique) via la signature f : Rx R → R. Étant donné deux vecteurs u et v de même forme, et un opérateur binaire f , nous pouvons produire un vecteur c = F(u, v) en posant ci ← f(ui, vi) pour tout i, où ci, ui et vi sont les ièmes éléments des vecteurs c, u et v. Ici, nous avons produit la valeur vectorielle $F :  R^{d} →R^{d} $ en élevant la fonction scalaire à une opération vectorielle élément par élément. Les opérateurs arithmétiques standard communs pour l'addition (+), la soustraction (-), la multiplication (*), la division (/) et l'exponentiation (**) ont tous été relevés en opérations élément par élément pour des tenseurs de forme identique de forme arbitraire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  4,  6, 10]),\n",
       " tensor([-1,  0,  2,  6]),\n",
       " tensor([ 2,  4,  8, 16]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1,  4, 16, 64]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1,2,4,8])\n",
    "\n",
    "y=torch.tensor([2,2,2,2])\n",
    "\n",
    "x+y,x-y,x*y,x/y,x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to elementwise computations, we can also perform linear algebra operations, such as dot products and matrix multiplications. We will elaborate on these shortly in Section2.3. We can also concatenate multiple tensors together, stacking them end-to-end to form a larger\n",
    "tensor. We just need to provide a list of tensors and tell the system along which axis to concatenate. The example below shows what happens when we concatenate two matrices along rows (axis 0) vs. columns (axis 1). We can see that the first output’s axis-0 length (6) is the sum of the two input tensors’ axis-0 lengths (3 + 3); while the second output’s axis-1 length (8) is the sum of the two input tensors’ axis-1 lengths (4 + 4).\n",
    "\n",
    "En plus des calculs élémentaires, nous pouvons également effectuer des opérations d'algèbre linéaire, telles que des produits scalaires et des multiplications matricielles. Nous les détaillerons brièvement dans la section 2.3. Nous pouvons également concaténer plusieurs tenseurs ensemble, en les empilant bout à bout pour former un plus grand\n",
    "tenseur. Nous avons juste besoin de fournir une liste de tenseurs et d'indiquer au système le long de quel axe concaténer. L'exemple ci-dessous montre ce qui se passe lorsque nous concaténons deux matrices le long des lignes (axe 0) par rapport aux colonnes (axe 1). Nous pouvons voir que la longueur de l'axe 0 de la première sortie (6)\n",
    "est la somme des longueurs d'axe-0 des deux tenseurs d'entrée (3 + 3); tandis que l'axe-1 de la deuxième sortie\n",
    "longueur (8) est la somme des longueurs axe-1 des deux tenseurs d'entrée (4 + 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[2., 1., 4., 3.],\n",
       "         [1., 2., 3., 4.],\n",
       "         [4., 3., 2., 1.]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [ 2.,  1.,  4.,  3.],\n",
       "        [ 1.,  2.,  3.,  4.],\n",
       "        [ 4.,  3.,  2.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((X, Y), dim=0)  # We add X and Y in the same tensor withouth changing their location and Y is under X:dim=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to construct a binary tensor via logical statements. Take X == Y as an example. For each position i, j, if X[i, j] and \n",
    "Y[i, j] are equal, then the corresponding entry in the result takes value 1, otherwise it takes value 0.\n",
    "\n",
    "Parfois, nous voulons construire un tenseur binaire via des instructions logiques. Prenons X == Y comme exemple. Pour chaque position i, j, \n",
    "si X[i, j] et Y[i, j] sont égaux, alors l'entrée correspondante dans le résultat prend la valeur 1, sinon elle prend la valeur 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X==Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing all the elements in the tensor yields a tensor with only one element.\n",
    "\n",
    "La somme de tous les éléments du tenseur donne un tenseur avec un seul élément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.4  Broadcasting : Diffusion\n",
    "\n",
    "By now, you know how to perform elementwise binary operations on two tensors of the same shape. Under certain conditions, even when shapes differ, we can still perform elementwise binary operations by invoking the broadcasting mechanism. Broadcasting works according to\n",
    "the following two-step procedure: (i) expand one or both arrays by copying elements along axes with length 1 so that after this transformation, the two tensors have the same shape; (ii) perform an elementwise operation on the resulting arrays.\n",
    "\n",
    "À présent, vous savez comment effectuer des opérations binaires élément par élément sur deux tenseurs du même forme. Dans certaines conditions, même lorsque les formes diffèrent, nous pouvons toujours effectuer par élément opérations binaires en invoquant le mécanisme de diffusion. La diffusion fonctionne selon la procédure en deux étapes suivante : (i) développer un ou les deux tableaux en copiant des éléments le long\n",
    "des axes de longueur 1 pour qu'après cette transformation, les deux tenseurs aient la même forme ; (ii) effectuer une opération élément par élément sur les tableaux résultants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up.Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows before adding them elementwise.\n",
    "\n",
    "Étant donné que a et b sont respectivement des matrices 3 × 1 et 1 × 2, leurs formes ne correspondent pas. La diffusion produit une matrice 3 × 2 plus grande en répliquant la matrice a le long des colonnes et la matrice b le long des lignes avant de les ajouter élément par élément."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a=\\begin{pmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "b=\\begin{pmatrix}\n",
    "0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "a+b=\\begin{pmatrix}\n",
    "0 +0 & 0+1 \\\\\n",
    "1 +0 & 1+1\\\\\n",
    "2+0 & 2+1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.5 Saving Memory : Enregistrement de la mémoire\n",
    "\n",
    "Running operations can cause new memory to be allocated to host results. For example, if we write Y = X + Y, we dereference the tensor that Y used to point to and instead point Y at the newly allocated memory. We can demonstrate this issue with Python’s id() function, which\n",
    "gives us the exact address of the referenced object in memory. Note that after we run Y = Y + X, id(Y) points to a different location. That is because Python first evaluates Y + X, allocating new memory for the result and then points Y to this new location in memory.\n",
    "\n",
    "Les opérations en cours d'exécution peuvent entraîner l'allocation de nouvelle mémoire aux résultats de l'hôte. Par exemple, si nous écrivons \n",
    "Y = X + Y, nous déréférencons le tenseur vers lequel Y pointait et pointons à la place Y vers la mémoire nouvellement allouée. Nous pouvons démontrer ce problème avec la fonction id() de Python, qui nous donne l'adresse exacte de l'objet référencé en mémoire. Notez qu'après avoir exécuté Y = Y + X, id(Y) pointe vers un emplacement différent. En effet, Python évalue d'abord Y + X, allouant une nouvelle mémoire pour le résultat, puis pointe Y vers ce nouvel emplacement en mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be undesirable for two reasons. First, we do not want to run around allocating memory unnecessarily all the time. In machine learning, we often have hundreds of megabytes of parameters and update all of them multiple times per second. Whenever possible, we want to perform these updates in place. Second, we might point at the same parameters from multiple variables. If we do not update in place, we must be careful to update all of these references, lest we spring a memory leak or inadvertently refer to stale parameters.\n",
    "\n",
    "Cela pourrait être indésirable pour deux raisons. Tout d'abord, nous ne voulons pas constamment allouer inutilement de la mémoire. Dans l'apprentissage automatique, nous avons souvent des centaines de mégaoctets de paramètres et nous les mettons tous à jour plusieurs fois par seconde. Dans la mesure du possible, nous souhaitons effectuer ces mises à jour sur place. Deuxièmement, nous pourrions désigner les mêmes paramètres à partir de plusieurs variables. Si nous ne mettons pas à jour sur place, nous devons veiller à mettre à jour toutes ces références, de peur de provoquer une fuite de mémoire ou de faire référence par inadvertance à des paramètres obsolètes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, performing in-place operations is easy. We can assign the result of an operation to a previously allocated array Y by using slice notation: Y[:] = <expression>. To illustrate this concept, we overwrite the values of tensor Z, after initializing it, using zeros_like, to\n",
    "have the same shape as Y.\n",
    "\n",
    "Heureusement, il est facile d'effectuer des opérations sur place. Nous pouvons affecter le résultat d'une opération à un tableau Y précédemment alloué en utilisant la notation de tranche : Y[:] = <expression>. Pour illustrer ce concept, nous écrasons les valeurs du tenseur Z, après l'avoir initialisé, en utilisant zeros_like, pour avoir la même forme que Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 1754519728592\n",
      "id(Z): 1754519728592\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the value of X is not reused in subsequent computations, we can also use X[:] = X + Y\n",
    "or X += Y to reduce the memory overhead of the operation.\n",
    "\n",
    "Si la valeur de X n'est pas réutilisée dans les calculs ultérieurs, nous pouvons également utiliser X[:] = X + Y\n",
    "ou X += Y pour réduire la surcharge mémoire de l'opération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.6 Conversion to Other Python Objects: Conversion vers d'autres objets Python\n",
    "\n",
    "Converting to a NumPy tensor (ndarray), or vice versa, is easy. The torch Tensor and numpy array will share their underlying memory, and changing one through an in-place operation will also change the other.\n",
    "\n",
    "La conversion en un tenseur NumPy (ndarray), ou vice versa, est facile. La torche Tensor et le tableau numpy partageront leur mémoire sous-jacente, et changer l'un via une opération sur place changera également l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a size-1 tensor to a Python scalar, we can invoke the item function or Python’s built-in functions.\n",
    "\n",
    "Pour convertir un tenseur de taille 1 en scalaire Python, nous pouvons invoquer la fonction d'élément ou les fonctions intégrées de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "float(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.7 Summary:  Résumé\n",
    "\n",
    "The tensor class is the main interface for storing and manipulating data in deep learning\n",
    "libraries. Tensors provide a variety of functionalities including construction routines; indexing and slicing; basic mathematics operations; broadcasting; memory-efficient assignment; and conversion to and from other Python objects.\n",
    "\n",
    "\n",
    "La classe tensor est la principale interface de stockage et de manipulation des données dans les bibliothèques d'apprentissage en profondeur. Les tenseurs offrent une variété de fonctionnalités, notamment des routines de construction ; indexage et trancher ; opérations mathématiques \n",
    "de base; diffusion; affectation efficace en mémoire ; et la conversion vers et depuis d'autres objets Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.8 Exercises\n",
    "\n",
    "1. Run the code in this section. Change the conditional statement X == Y to X < Y or X > Y, and then see what kind of tensor you can get.\n",
    "\n",
    "1. Exécutez le code dans cette section. Remplacez l'instruction conditionnelle X == Y par X < Y ou X > Y, puis voyez quel type de tenseur \n",
    "vous  pouvez obtenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X < Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [ True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X > Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Replace the two tensors that operate by element in the broadcasting mechanism with other\n",
    "shapes, e.g., 3-dimensional tensors. Is the result the same as expected?\n",
    "\n",
    "2. Remplacer les deux tenseurs qui fonctionnent par élément dans le mécanisme de diffusion par d'autres\n",
    "formes, par exemple, des tenseurs tridimensionnels. Le résultat est-il le même que prévu ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(1,6,dtype=torch.float32).reshape((5,1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.arange(1,3).reshape((1,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 3.],\n",
       "         [3., 4.],\n",
       "         [4., 5.],\n",
       "         [5., 6.],\n",
       "         [6., 7.]]),\n",
       " tensor([[ 0., -1.],\n",
       "         [ 1.,  0.],\n",
       "         [ 2.,  1.],\n",
       "         [ 3.,  2.],\n",
       "         [ 4.,  3.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b,a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price \n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')\n",
    "#import pandas as pd\n",
    "#data = pd.read_csv(data_file)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Data Preprocessing : Prétraitement des données\n",
    "\n",
    "So far, we have been working with synthetic data that arrived in ready-made tensors. However,to apply deep learning in the wild we must extract messy data stored in arbitrary formats, and preprocess it to suit our needs. Fortunately, the pandas library44 can do much of the heavy\n",
    "lifting. This section, while no substitute for a proper pandas tutorial45 , will give you a crash course on some of the most common routines.\n",
    "\n",
    "Jusqu'à présent, nous avons travaillé avec des données synthétiques qui sont arrivées dans des tenseurs prêts à l'emploi. Cependant, pour appliquer l'apprentissage en profondeur dans la nature, nous devons extraire des données désordonnées stockées dans des formats arbitraires et les prétraiter en fonction de nos besoins. Heureusement, la bibliothèque de pandas44 peut faire une grande partie du lourd\n",
    "levage. Cette section, bien qu'elle ne remplace pas un véritable didacticiel sur les pandas45 , vous donnera un cours accéléré sur certaines des routines les plus courantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s import pandas and load the dataset with read_csv.\n",
    "\n",
    "Importons maintenant des pandas et chargeons le jeu de données avec read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType  Price \n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2 Data Preparation: Préparation des données\n",
    "\n",
    "In supervised learning, we train models to predict a designated target value, given some set of input values. Our first step in processing the dataset is to separate out columns corresponding to input versus target values. We can select columns either by name or via integer-location\n",
    "based indexing (iloc). \n",
    "\n",
    "\n",
    "Dans l'apprentissage supervisé, nous formons des modèles pour prédire une valeur cible désignée, étant donné un ensemble de valeurs d'entrée. Notre première étape dans le traitement de l'ensemble de données consiste à séparer les colonnes correspondant aux valeurs d'entrée par rapport aux valeurs cibles. Nous pouvons sélectionner des colonnes soit par nom, soit via un emplacement entier\n",
    "indexation basée (iloc).\n",
    "\n",
    "\n",
    "You might have noticed that pandas replaced all CSV entries with value NA with a special NaN (not a number) value. This can also happen whenever an entry is empty, e.g., “3,,,270000”. These are called missing values and they are the “bed bugs” of data science, a persistent\n",
    "menace that you will confront throughout your career. Depending upon the context, missing values might be handled either via imputation or deletion. Imputation replaces missing values with estimates of their values while deletion simply discards either those rows or those\n",
    "columns that contain missing values.\n",
    "\n",
    "Vous avez peut-être remarqué que les pandas ont remplacé toutes les entrées CSV avec la valeur NA par une valeur spéciale NaN (pas un nombre). Cela peut également se produire chaque fois qu'une entrée est vide, par exemple \"3,,,270000\". Ce sont ce qu'on appelle les valeurs manquantes et ce sont les « punaises de lit » de la science des données, un problème persistant.\n",
    "menace à laquelle vous serez confronté tout au long de votre carrière. Selon le contexte, les valeurs manquantes peuvent être traitées soit par imputation, soit par suppression. L'imputation remplace les valeurs manquantes par des estimations de leurs valeurs tandis que la suppression supprime simplement ces lignes ou celles colonnes contenant des valeurs manquantes.\n",
    "\n",
    "\n",
    "Here are some common imputation heuristics. For categorical input fields, we can treat NaN as a category. Since the RoofType column takes values Slate and NaN, pandas can convert this column into two columns RoofType_Slate and RoofType_nan. A row whose roof type is Slate will set values of RoofType_Slate and RoofType_nan to 1 and 0, respectively. The converse holds for a row with a missing RoofType value.\n",
    "\n",
    "\n",
    "Voici quelques heuristiques d'imputation courantes. Pour les champs de saisie catégoriels, nous pouvons traiter NaN comme une catégorie. Puisque la colonne RoofType prend les valeurs Slate et NaN, les pandas peuvent convertir cette colonne en deux colonnes RoofType_Slate et RoofType_nan. Une ligne dont le type de toit est Ardoise définira les valeurs de RoofType_Slate et RoofType_nan sur 1 et 0, respectivement. L'inverse est vrai pour une ligne avec une valeur RoofType manquante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       NaN             0.0           1.0\n",
      "1       2.0             0.0           1.0\n",
      "2       4.0             1.0           0.0\n",
      "3       NaN             0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "#pd.get_dummies(pd.Series(list('abc')), dtype=float)\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True ,dtype=float)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For missing numerical values, one common heuristic is to replace the NaN entries with the mean value of the corresponding column.\n",
    "\n",
    "Pour les valeurs numériques manquantes, une heuristique courante consiste à remplacer les entrées NaN par la valeur moyenne de la colonne correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0             0.0           1.0\n",
      "1       2.0             0.0           1.0\n",
      "2       4.0             1.0           0.0\n",
      "3       3.0             0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.3 Conversion to the Tensor Format:Conversion au format tenseur\n",
    "Now that all the entries in inputs and targets are numerical, we can load them into a tensor (recall Section 2.1).\n",
    "\n",
    "Maintenant que toutes les entrées dans les entrées et les cibles sont numériques, nous pouvons les charger dans un tenseur \n",
    "(rappelons la section 2.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(targets.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.4 Discussion: \n",
    "You now know how to partition data columns, impute missing variables, and load pandas data into tensors. In Section 5.7, you will pick up some more data processing skills. While this crash course kept things simple, data processing can get hairy. For example, rather than\n",
    "arriving in a single CSV file, our dataset might be spread across multiple files extracted from a relational database. For instance, in an e-commerce application, customer addresses might live in one table and purchase data in another. Moreover, practitioners face myriad data types\n",
    "beyond categorical and numeric. Other data types include text strings, images, audio data, and point clouds. Oftentimes, advanced tools and efficient algorithms are required to prevent data processing from becoming the biggest bottleneck in the machine learning pipeline. These\n",
    "problems will arise when we get to computer vision and natural language processing. Finally, we must pay attention to data quality. Real-world datasets are often plagued by outliers, faulty measurements from sensors, and recording errors, which must be addressed before feeding\n",
    "the data into any model. Data visualization tools such as seaborn46 , Bokeh47 , or matplotlib 48 can help you to manually inspect the data and develop intuitions about what problems you may need to address.\n",
    "\n",
    "Vous savez maintenant comment partitionner des colonnes de données, imputer des variables manquantes et charger des données pandas dans des tenseurs. Dans la section 5.7, vous acquerrez d'autres compétences en traitement de données. Bien que ce cours intensif ait simplifié les choses, le traitement des données peut devenir compliqué. Par exemple, plutôt que arrivant dans un seul fichier CSV, notre jeu de données peut être réparti sur plusieurs fichiers extraits d'une base de données relationnelle. Par exemple, dans une application de commerce électronique, les adresses des clients peuvent résider dans une table et  des données d'achat dans une autre. De plus, les praticiens sont confrontés à une myriade de types de données au-delà du catégorique et du numérique. Les autres types de données incluent les chaînes de texte, les images, les données audio et les nuages ​​de points. Souvent, des outils avancés et des algorithmes efficaces sont nécessaires pour éviter que le traitement des données ne devienne le plus gros goulot d'étranglement du pipeline d'apprentissage automatique. Ces\n",
    "des problèmes surgiront lorsque nous arriverons à la vision par ordinateur et au traitement du langage naturel. Enfin, il faut faire attention à la qualité des données. Les ensembles de données du monde réel sont souvent en proie à des valeurs aberrantes, des mesures erronées des capteurs et des erreurs d'enregistrement, qui doivent être corrigées avant l'alimentation\n",
    "les données dans n'importe quel modèle. Des outils de visualisation de données tels que seaborn46 , Bokeh47 ou matplotlib 48 peuvent vous aider à inspecter manuellement les données et à développer des intuitions sur les problèmes que vous devrez peut-être résoudre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        2.2.5 Exercises\n",
    "1. Try loading datasets, e.g., Abalone from the UCI Machine Learning Repository 49 and inspect their properties. What fraction of them has missing values? What fraction of the variables is numerical, categorical, or text?\n",
    "2. Try out indexing and selecting data columns by name rather than by column number. The pandas documentation on indexing50 has further details on how to do this.\n",
    "3. How large a dataset do you think you could load this way? What might be the limitations?\n",
    "Hint: consider the time to read the data, representation, processing, and memory footprint. Try this out on your laptop. What changes if you try it out on a server?\n",
    "4. How would you deal with data that has a very large number of categories? What if the category labels are all unique? Should you include the latter?\n",
    "5. What alternatives to pandas can you think of? How about loading NumPy tensors from a file51 ? Check out Pillow52 , the Python Imaging Library\n",
    "\n",
    "1. Essayez de charger des ensembles de données, par exemple, Abalone à partir du référentiel d'apprentissage automatique UCI 49 et inspectez leurs propriétés. Quelle fraction d'entre eux a des valeurs manquantes ? Quelle fraction des variables est numérique, catégorique ou textuelle ?\n",
    "2. Essayez d'indexer et de sélectionner des colonnes de données par nom plutôt que par numéro de colonne. La documentation de pandas sur l'indexation50 contient plus de détails sur la façon de procéder.\n",
    "3. Quelle taille d'ensemble de données pensez-vous pouvoir charger de cette façon ? Quelles pourraient être les limites ?\n",
    "Astuce : tenez compte du temps de lecture des données, de la représentation, du traitement et de l'empreinte mémoire. Essayez ceci sur votre ordinateur portable. Qu'est-ce qui change si vous l'essayez sur un serveur ?\n",
    "4. Comment traiteriez-vous des données comportant un très grand nombre de catégories ? Et si les étiquettes de catégorie étaient toutes uniques ? Faut-il inclure ce dernier ?\n",
    "5. À quelles alternatives aux pandas pouvez-vous penser ? Que diriez-vous de charger des tenseurs NumPy à partir d'un file51 ? Découvrez Pillow52 , la bibliothèque d'imagerie Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(os.path.join('..', 'abalone_data'), exist_ok=True)\n",
    "abalone_data_file = os.path.join('..', 'abalone_data', 'abalone_tiny.csv')\n",
    "with open(abalone_data_file, 'w') as f:\n",
    "    f.write('''Sex,length,diameter\n",
    "4177,4177,4177\n",
    "3,NA,NA\n",
    "M,NA,NA\n",
    "1528,NA,NA\n",
    "NA,0.523992,0.407881\n",
    "NA,0.120093,0.098240\n",
    "NA,0.075,0.055\n",
    "NA,0.45,0.35\n",
    "NA,0.545,0.425''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sex       length     diameter\n",
      "0  4177  4177.000000  4177.000000\n",
      "1     3          NaN          NaN\n",
      "2     M          NaN          NaN\n",
      "3  1528          NaN          NaN\n",
      "4   NaN     0.523992     0.407881\n",
      "5   NaN     0.120093     0.098240\n",
      "6   NaN     0.075000     0.055000\n",
      "7   NaN     0.450000     0.350000\n",
      "8   NaN     0.545000     0.425000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(abalone_data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        length     diameter  Sex_1528  Sex_3  Sex_4177  Sex_M  Sex_nan\n",
      "0  4177.000000  4177.000000       0.0    0.0       1.0    0.0      0.0\n",
      "1          NaN          NaN       0.0    1.0       0.0    0.0      0.0\n",
      "2          NaN          NaN       0.0    0.0       0.0    1.0      0.0\n",
      "3          NaN          NaN       1.0    0.0       0.0    0.0      0.0\n",
      "4     0.523992     0.407881       0.0    0.0       0.0    0.0      1.0\n",
      "5     0.120093     0.098240       0.0    0.0       0.0    0.0      1.0\n",
      "6     0.075000     0.055000       0.0    0.0       0.0    0.0      1.0\n",
      "7     0.450000     0.350000       0.0    0.0       0.0    0.0      1.0\n",
      "8     0.545000     0.425000       0.0    0.0       0.0    0.0      1.0\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = data.iloc[:, 0:3], data.iloc[:, 2]\n",
    "#pd.get_dummies(pd.Series(list('abc')), dtype=float)\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True ,dtype=float)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        length     diameter\n",
      "0  4177.000000  4177.000000\n",
      "1          NaN          NaN\n",
      "2          NaN          NaN\n",
      "3          NaN          NaN\n",
      "4     0.523992     0.407881\n"
     ]
    }
   ],
   "source": [
    "#abalone_data[[\"sex\", \"rings\", \"length\"]][ : 20]\n",
    "#abalone_data_file[[\"Sex\",\"length\"]][:9]\n",
    "print(inputs[[\"length\",\"diameter\"]][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        length     diameter  Sex_1528  Sex_3  Sex_4177  Sex_M  Sex_nan\n",
      "0  4177.000000  4177.000000       0.0    0.0       1.0    0.0      0.0\n",
      "1   696.452348   696.389354       0.0    1.0       0.0    0.0      0.0\n",
      "2   696.452348   696.389354       0.0    0.0       0.0    1.0      0.0\n",
      "3   696.452348   696.389354       1.0    0.0       0.0    0.0      0.0\n",
      "4     0.523992     0.407881       0.0    0.0       0.0    0.0      1.0\n",
      "5     0.120093     0.098240       0.0    0.0       0.0    0.0      1.0\n",
      "6     0.075000     0.055000       0.0    0.0       0.0    0.0      1.0\n",
      "7     0.450000     0.350000       0.0    0.0       0.0    0.0      1.0\n",
      "8     0.545000     0.425000       0.0    0.0       0.0    0.0      1.0\n"
     ]
    }
   ],
   "source": [
    "#inputs = inputs.fillna(inputs.mean()) ,print(inputs)\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.1770e+03, 4.1770e+03, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [5.2399e-01, 4.0788e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [1.2009e-01, 9.8240e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [7.5000e-02, 5.5000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [4.5000e-01, 3.5000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [5.4500e-01, 4.2500e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00]], dtype=torch.float64),\n",
       " tensor([4.1770e+03,        nan,        nan,        nan, 4.0788e-01, 9.8240e-02,\n",
       "         5.5000e-02, 3.5000e-01, 4.2500e-01], dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(targets.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.1770e+03, 4.1770e+03, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.9645e+02, 6.9639e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [5.2399e-01, 4.0788e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [1.2009e-01, 9.8240e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [7.5000e-02, 5.5000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [4.5000e-01, 3.5000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00],\n",
       "         [5.4500e-01, 4.2500e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00]], dtype=torch.float64),\n",
       " tensor([4.1770e+03,        nan,        nan,        nan, 4.0788e-01, 9.8240e-02,\n",
       "         5.5000e-02, 3.5000e-01, 4.2500e-01], dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(targets.values)\n",
    "X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
